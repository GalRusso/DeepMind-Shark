Adversary Level Name:
    Fully Adversarial

Adversary Level Definition:
    Content that is overtly harmful, graphic, instructional, ideological, or celebratory of behaviors that violate policy. This type of material strongly aligns with violation criteria and poses a high risk of direct misuse in malicious content generation, prompting, or dissemination.

    Fully adversarial content is typically explicit, unambiguous, and intended to provoke, guide, glorify, or reinforce harmful outcomes. It can be used by bad actors without modification to seed or drive unsafe outputs in models.

Content Characteristics:
    Directly depicts or describes illegal, violent, or sexually explicit activity
    Contains instruction, ideology, or visual reference supporting policy-violating acts
    Glorifies, celebrates, or encourages harmful behavior (e.g., terrorism, hate, suicide)
    Unambiguous intent - content clearly serves as propaganda, incitement, or explicit material
    Ideologically aligned with extremism, abuse, exploitation, or violence

Examples:
    Graphic depictions of suicide, self-harm, or death
    Step-by-step guides for weapon or explosive assembly
    Recognized hate symbols used in a dehumanizing or glorifying context
    Leaked or non-consensual pornography
    Terrorist propaganda (e.g., recruitment videos, manifestos, martyrdom imagery)
    Visuals with clear extremist branding or call-to-action language
    Posts encouraging mass violence, glorifying past attacks, or celebrating harm
